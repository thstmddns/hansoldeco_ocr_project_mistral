import os
import re
import time
import base64
import logging
import difflib
import tempfile
import pandas as pd
from concurrent.futures import ProcessPoolExecutor, as_completed
from mistralai import Mistral
from httpx import HTTPStatusError
import streamlit as st
from classify import classify_and_move_files
import shutil

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
api_key = st.secrets["MISTRAL_API_KEY"]
if not api_key:
    raise EnvironmentError("MISTRAL_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
client = Mistral(api_key=api_key)

def parse_data_from_template(text):
    LABELS = ["í˜„ì¥ëª…", "ê³µì¢…", "ë™í˜¸ìˆ˜", "ìœ„ì¹˜", "í•˜ììœ í˜•", "ì¼ì", "ì¹˜ìˆ˜", "ë¹„ê³ ", "í˜„í™©"]
    data = {}
    for line in text.splitlines():
        if ':' not in line:
            continue
        key, val = map(str.strip, line.split(':', 1))
        if key in LABELS:
            data[key] = val
    return data

def get_keyword_categories():
    return {
        'ë‹¨ì°¨ë¶ˆëŸ‰': ['ë‹¨ì°¨ë¶ˆëŸ‰', 'ë‹¨ì°¨'],
        "í›¼ì†": ["í›¼ì†", "ì°¢ê¹€", "ê¸í˜", "íŒŒì†", "ê¹¨ì§", "ê°ˆë¼ì§", "ì°í˜", "ìŠ¤í¬ë˜ì¹˜", "ì†ìƒ", "ëœ¯ê¹€", "ì°¢ì–´ì§", "ì¹¼ìêµ­", "í„°ì§", "ê¹Œì§", "í ì§‘",
                 "ì°ê¹€", "ì›¨ì†", "ê¸í—˜", "ì°í—˜", "ì°ì„", "ì§í˜", "ê¸ë¦¼", "ê¸ì„", "ì°¢ì‹¬", "íšŸì†", "ì°¢ê²€", "ì°¢ê°"],
        "ì˜¤ì—¼": ["ì˜¤ì—¼", "ë”ëŸ¬ì›€", "ì–¼ë£©", "ë³€ìƒ‰", "ë‚™ì„œ"],
        "ëˆ„ìˆ˜ ë° ê³°íŒ¡ì´": ["ê³°íŒ¡ì´", "ëˆ„ìˆ˜", "ê³§ê´‘ì´", "ê³°ê´‘ì´"],
        "ë©´ë¶ˆëŸ‰": ["ë©´ë¶ˆëŸ‰", "ë©´ ë¶ˆëŸ‰", "í¼í‹°", "ëŒì¶œ", "ì´ë¬¼ì§ˆ", "ëŒê¸°", "ë²½ë©´ë¶ˆ", "ë©´ë¶ˆë‘"],
        'ë“¤ëœ¸': ["ë“¤ëœ¸", "ë“¤ëœ°", "ë“¤í””", "ë“¤ë“¬", "ë“¤ìŒ", "ë“¤ë“±", "ë‘˜ëœ¸", "ë“¤ëœ¯", "ëŒëœ¸"],
        'ê¼¬ì„': ["ê¼¬ì„"], 'ì£¼ë¦„': ["ì£¼ë¦„"], 'ìš¸ìŒ': ["ìš¸ìŒ"],
        "ì„ê³ ìˆ˜ì •": ["ì„ê³ ", "ì„ê³ ìˆ˜ì •", "ì„ê³ ë³´ë“œ", "ì„ê³ ì‘ì—…", "ì„ê³ ë©´ë¶ˆëŸ‰"],
        "ëª°ë”©ìˆ˜ì •": ["ëª°ë”©", "ëª°ë”©ìˆ˜ì •", "ëª°ë”©êµì²´", "ëª°ë”©ì‘ì—…", "ëŒë”©", "ì˜¬ë”©"],
        'ê±¸ë ˆë°›ì´ ìˆ˜ì •': ["ê±¸ë ˆë°›ì´", "ê±¸ë˜ë°›ì´", "ê±¸ë ˆë°›ì§€", "ê±¸ë ˆë°›ì´ìˆ˜ì •", "ê±¸ë ˆë°›ì´ êµì²´", "ê±¸ë ˆë°›ì´ ì‘ì—…"],
        'ë¬¸í‹€ìˆ˜ì •': ["ë¬¸í‹€ìˆ˜ì •", "ë¬¸í‹€"],
        'ê°€êµ¬ìˆ˜ì •': ["ê°€êµ¬", "ê°€êµ¬ìˆ˜ì •"],
        'í‹ˆìƒˆ': ["í‹ˆìƒˆ", "í‹ˆìƒˆìˆ˜ì •", "í‹ˆìƒˆê³¼ë‹¤", "ë²Œì–´ì§"],
        'í•©íŒ': ["í•©íŒê¸¸ì´ë¶€ì¡±", "í•©íŒ"],
        'ê²°ë¡œ': ["ê²°ë¡œ"],
        'ì´ìŒìƒˆ': ["ì´ìŒìƒˆ", "ì´ìŒ"],
        "ì˜¤íƒ€ê³µ": ["ì˜¤íƒ€ê³µ", "ì˜¤íƒ€ì½©", "íƒ€ê³µê³¼ë‹¤", "í”¼ìŠ¤íƒ€ê³µ", "ê³¼íƒ€ê³µ", "íƒ€ê³µ"],
        "ë‚´ì¥í›„ì†": ['ë‚´ì¥í›„ì†', 'ë‚´ì¥ í›„ì†'],
        "íƒˆë½": ["íƒˆë½"],
        "ë§ˆê°ë¶ˆëŸ‰": ["ë§ˆê°ë¶ˆëŸ‰"],
    }

def classify_defect(text):
    categories = get_keyword_categories()
    matched = set()
    words = re.split(r'\s+', text.lower())
    for cat, keywords in categories.items():
        for kw in keywords:
            for word in words:
                if kw in word or difflib.SequenceMatcher(None, kw, word).ratio() > 0.8:
                    matched.add(cat)
                    break
    return ", ".join(sorted(matched)) if matched else ""

def extract_dong_ho(location_text):
    dash_match = re.search(r'\b(\d+)-(\d+)\b', location_text)
    if dash_match:
        return dash_match.group(1), dash_match.group(2)
    dong_match = re.search(r'(\d+)\s*ë™', location_text)
    ho_match = re.search(r'(\d+)\s*í˜¸', location_text)
    dong = dong_match.group(1) if dong_match else ""
    ho = ho_match.group(1) if ho_match else ""
    if not dong or not ho:
        nums = re.findall(r'\d+', location_text)
        if len(nums) == 2:
            dong = dong or nums[0]
            ho = ho or nums[1]
    return dong, ho

def extract_text_from_image(image_path, max_retries=3, backoff=2):
    with open(image_path, "rb") as f:
        image_data = base64.b64encode(f.read()).decode("utf-8")

    for attempt in range(max_retries):
        try:
            response = client.ocr.process(
                model="mistral-ocr-latest",
                document={
                    "type": "image_url",
                    "image_url": f"data:image/jpeg;base64,{image_data}"
                },
                include_image_base64=False
            )
            time.sleep(1.2)

            data = response.model_dump()

            if data.get("text"):
                return data["text"]

            if "pages" in data and "markdown" in data["pages"][0]:
                markdown = data["pages"][0]["markdown"]
                lines = []
                for line in markdown.splitlines():
                    if line.startswith("|") and line.count("|") >= 3:
                        parts = [part.strip() for part in line.strip().split("|")[1:-1]]
                        if len(parts) == 2:
                            key, value = parts
                            lines.append(f"{key}: {value}")
                return "\n".join(lines).strip()

            return ""

        except HTTPStatusError as e:
            if e.response.status_code == 429:
                wait_time = backoff * (attempt + 1)
                logging.warning(f"429 Too Many Requests - {wait_time}ì´ˆ í›„ ì¬ì‹œë„")
                time.sleep(wait_time)
            else:
                raise
        except Exception as e:
            logging.error(f"OCR ì‹¤íŒ¨: {e}")
            raise
    raise RuntimeError("ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼")

def process_one_image(file_path):
    filename = os.path.basename(file_path)
    try:
        raw_text = extract_text_from_image(file_path)
    except Exception as e:
        logging.warning(f"[ì˜¤ë¥˜] {filename} OCR ì‹¤íŒ¨: {e}")
        return None

    parsed = parse_data_from_template(raw_text)
    for fld in ["í˜„ì¥ëª…", "ê³µì¢…", "ë™í˜¸ìˆ˜", "ìœ„ì¹˜", "í•˜ììœ í˜•", "ì¼ì", "ì¹˜ìˆ˜", "ë¹„ê³ ", "í˜„í™©"]:
        parsed.setdefault(fld, "")

    dong, ho = extract_dong_ho(parsed["ë™í˜¸ìˆ˜"])
    keyword = classify_defect(parsed["í•˜ììœ í˜•"])

    return {
        "íŒŒì¼ëª…": filename,
        "í˜„ì¥ëª…": parsed["í˜„ì¥ëª…"],
        "ê³µì¢…": parsed["ê³µì¢…"],
        "ë™í˜¸ìˆ˜": parsed["ë™í˜¸ìˆ˜"],
        "ë™": dong,
        "í˜¸": ho,
        "ìœ„ì¹˜": parsed["ìœ„ì¹˜"],
        "í•˜ììœ í˜•": parsed["í•˜ììœ í˜•"],
        "í‚¤ì›Œë“œ": keyword,
        "ì¼ì": parsed["ì¼ì"],
        "ì¹˜ìˆ˜": parsed["ì¹˜ìˆ˜"],
        "ë¹„ê³ ": parsed["ë¹„ê³ "],
        "í˜„í™©": parsed["í˜„í™©"]
    }

def process_images_to_excel(folder_path, max_workers=1):
    valid_exts = (".jpg", ".jpeg", ".png", ".bmp", ".tif")
    file_list = [
        os.path.join(folder_path, f)
        for f in os.listdir(folder_path)
        if os.path.isfile(os.path.join(folder_path, f)) and f.lower().endswith(valid_exts)
    ]

    records = []
    progress_bar = st.progress(0, text="ì´ë¯¸ì§€ OCR ì§„í–‰ ì¤‘...")
    total = len(file_list)
    completed = 0
    
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(process_one_image, fp): fp for fp in file_list}
        for future in as_completed(futures):
            rec = future.result()
            if rec is not None:
                records.append(rec)
            completed += 1
            progress_bar.progress(completed / total, text=f"{completed}/{total} ì²˜ë¦¬ ì™„ë£Œ")

    progress_bar.empty()
    
    if records:
        columns = [
            "íŒŒì¼ëª…", "í˜„ì¥ëª…", "ê³µì¢…", "ë™í˜¸ìˆ˜", "ë™", "í˜¸",
            "ìœ„ì¹˜", "í•˜ììœ í˜•", "í‚¤ì›Œë“œ", "ì¼ì", "ì¹˜ìˆ˜", "ë¹„ê³ ", "í˜„í™©"
        ]
        df = pd.DataFrame(records, columns=columns)
        df["ë™"] = pd.to_numeric(df["ë™"], errors="coerce").astype("Int64")
        df["í˜¸"] = pd.to_numeric(df["í˜¸"], errors="coerce").astype("Int64")
        df["íŒŒì¼ë§í¬"] = df.apply(
            lambda row: f'=HYPERLINK("{row["í‚¤ì›Œë“œ"].split(",")[0]}/{row["íŒŒì¼ëª…"]}", "{row["íŒŒì¼ëª…"]}")',
            axis=1
        )
        df = df[["íŒŒì¼ëª…", "íŒŒì¼ë§í¬"] + columns[1:]]
        excel_path = os.path.join(folder_path, "results_mistral_ocr.xlsx")
        df.to_excel(excel_path, index=False)
        logging.info(f"[ì™„ë£Œ] ì—‘ì…€ ì €ì¥: {excel_path}")
    else:
        logging.warning(f"[ì£¼ì˜] ìœ íš¨í•œ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {folder_path}")

def run_all_steps():
    excel_path = os.path.join(st.session_state.uploaded_dir, "results_mistral_ocr.xlsx")
    classified_dir = os.path.join(tempfile.mkdtemp(), "classified")
    os.makedirs(classified_dir, exist_ok=True)

    # íŒŒì¼ ë¶„ë¥˜ ìˆ˜í–‰
    classify_and_move_files(excel_path, st.session_state.uploaded_dir)

    # ì—‘ì…€ ë³µì‚¬
    shutil.copy(excel_path, os.path.join(classified_dir, "results_mistral_ocr.xlsx"))

    # í•˜ìœ„ í´ë”(ë¶„ë¥˜ëœ í•˜ììœ í˜• í´ë”ë“¤) ë³µì‚¬
    for subdir in os.listdir(st.session_state.uploaded_dir):
        full_path = os.path.join(st.session_state.uploaded_dir, subdir)
        if os.path.isdir(full_path):
            shutil.copytree(full_path, os.path.join(classified_dir, subdir), dirs_exist_ok=True)

    # zipìœ¼ë¡œ ì••ì¶•
    zip_path = shutil.make_archive(classified_dir, 'zip', classified_dir)
    return zip_path


# Streamlit UI
st.title('HOPEZIP')
st.header('Hansoldeco OCR Project Extraction ZIP')

uploaded_files = st.file_uploader("ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", accept_multiple_files=True)

if uploaded_files:
    if "uploaded_dir" not in st.session_state:
        st.session_state.uploaded_dir = tempfile.mkdtemp()

    uploaded_dir = st.session_state.uploaded_dir

    for file in uploaded_files:
        save_path = os.path.join(uploaded_dir, file.name)
        with open(save_path, "wb") as f:
            f.write(file.read())

    if st.button("ğŸ” OCR ë° ì—‘ì…€ ìƒì„±"):
        process_images_to_excel(uploaded_dir, max_workers=1)
        st.session_state.ocr_done = True
        st.success("OCR ì™„ë£Œ ë° ì—‘ì…€ ìƒì„± ì™„ë£Œ")

    excel_path = os.path.join(uploaded_dir, "results_mistral_ocr.xlsx")

    if os.path.exists(excel_path):
        col1, col2, col3 = st.columns(3)

        with col1:
            st.download_button(
                label="ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                data=open(excel_path, "rb").read(),
                file_name="results_mistral_ocr.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key="excel_download"
            )

        with col2:
            with st.spinner("ZIP ìƒì„± ì¤‘..."):
                zip_path = run_all_steps()
                with open(zip_path, "rb") as f:
                    zip_data = f.read()
            st.download_button(
                label="ğŸ“¦ ZIP ë‹¤ìš´ë¡œë“œ",
                data=zip_data,
                file_name="classified_files_with_excel.zip",
                mime="application/zip",
                key="zip_download"
            )


        # if st.button("ğŸ“‚ íŒŒì¼ ë¶„ë¥˜ ë° ì—‘ì…€ ZIP ë‹¤ìš´ë¡œë“œ"):
        #     classified_dir = os.path.join(tempfile.mkdtemp(), "classified")
        #     os.makedirs(classified_dir, exist_ok=True)

        #     classify_and_move_files(excel_path, uploaded_dir)
        #     shutil.copy(excel_path, os.path.join(classified_dir, "results_mistral_ocr.xlsx"))

        #     for subdir in os.listdir(uploaded_dir):
        #         full_path = os.path.join(uploaded_dir, subdir)
        #         if os.path.isdir(full_path):
        #             shutil.copytree(full_path, os.path.join(classified_dir, subdir), dirs_exist_ok=True)

        #     zip_path = shutil.make_archive(classified_dir, 'zip', classified_dir)

        #     with open(zip_path, "rb") as f:
        #         st.download_button(
        #             label="ğŸ“¦ ZIP ë‹¤ìš´ë¡œë“œ",
        #             data=f.read(),
        #             file_name="classified_files_with_excel.zip",
        #             mime="application/zip"
        #         )
    else:
        st.info("ì•„ì§ OCRì´ ìˆ˜í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € 'OCR ë° ì—‘ì…€ ìƒì„±'ì„ í´ë¦­í•˜ì„¸ìš”.")


